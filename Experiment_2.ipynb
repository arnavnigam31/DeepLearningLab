{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Beu-5aXu-RIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5066a56-7c88-4d58-f6ca-f2d1307da86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.07MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.49MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.44MB/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "val_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v2QbY-eU-nYx"
      },
      "outputs": [],
      "source": [
        "def one_hot(y, num_classes=10):\n",
        "    oh = np.zeros((y.shape[0], num_classes))\n",
        "    oh[np.arange(y.shape[0]), y] = 1\n",
        "    return oh\n",
        "\n",
        "def preprocess(images, labels):\n",
        "    images = images.cpu().numpy()\n",
        "    labels = labels.cpu().numpy()\n",
        "\n",
        "    images = images / 1.0\n",
        "\n",
        "    #Flatten: (B,1,28,28) → (B,784)\n",
        "    images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "    labels = one_hot(labels)\n",
        "    return images, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AtExrHOO-pck"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_deriv(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_deriv(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_deriv(x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q3htDLoo-rcD"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, layer_sizes, activation='relu', lr=0.01):\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.lr = lr\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        for i in range(len(layer_sizes)-1):\n",
        "            w = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2/layer_sizes[i])\n",
        "            b = np.zeros((1, layer_sizes[i+1]))\n",
        "            self.weights.append(w)\n",
        "            self.biases.append(b)\n",
        "\n",
        "        if activation == 'relu':\n",
        "            self.act = relu\n",
        "            self.act_deriv = relu_deriv\n",
        "        elif activation == 'sigmoid':\n",
        "            self.act = sigmoid\n",
        "            self.act_deriv = sigmoid_deriv\n",
        "        elif activation == 'tanh':\n",
        "            self.act = tanh\n",
        "            self.act_deriv = tanh_deriv\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z = []\n",
        "        self.a = [X]\n",
        "\n",
        "        for i in range(len(self.weights)-1):\n",
        "            z = self.a[-1] @ self.weights[i] + self.biases[i]\n",
        "            a = self.act(z)\n",
        "            self.z.append(z)\n",
        "            self.a.append(a)\n",
        "\n",
        "        # Output layer (Softmax)\n",
        "        z = self.a[-1] @ self.weights[-1] + self.biases[-1]\n",
        "        a = softmax(z)\n",
        "        self.z.append(z)\n",
        "        self.a.append(a)\n",
        "\n",
        "        return a\n",
        "\n",
        "\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        m = y_true.shape[0]\n",
        "        loss = -np.sum(y_true * np.log(y_pred + 1e-9)) / m\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def backward(self, y_true):\n",
        "        m = y_true.shape[0]\n",
        "\n",
        "        dW = [None]*len(self.weights)\n",
        "        dB = [None]*len(self.biases)\n",
        "\n",
        "\n",
        "        dz = self.a[-1] - y_true\n",
        "        dW[-1] = self.a[-2].T @ dz / m\n",
        "        dB[-1] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Hidden layers\n",
        "        for i in reversed(range(len(self.weights)-1)):\n",
        "            dz = (dz @ self.weights[i+1].T) * self.act_deriv(self.z[i])\n",
        "            dW[i] = self.a[i].T @ dz / m\n",
        "            dB[i] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "        self.dW = dW\n",
        "        self.dB = dB\n",
        "\n",
        "    def update_parameters(self):\n",
        "        for i in range(len(self.weights)):\n",
        "            self.weights[i] -= self.lr * self.dW[i]\n",
        "            self.biases[i] -= self.lr * self.dB[i]\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        probs = self.forward(X)\n",
        "        return np.argmax(probs, axis=1)\n",
        "\n",
        "    def evaluate(self, loader):\n",
        "        total_loss, total_correct, total = 0, 0, 0\n",
        "        for images, labels in loader:\n",
        "            X, y = preprocess(images, labels)\n",
        "            y_pred = self.forward(X)\n",
        "            loss = self.compute_loss(y_pred, y)\n",
        "\n",
        "            preds = np.argmax(y_pred, axis=1)\n",
        "            true = np.argmax(y, axis=1)\n",
        "\n",
        "            total_loss += loss * X.shape[0]\n",
        "            total_correct += np.sum(preds == true)\n",
        "            total += X.shape[0]\n",
        "\n",
        "        return total_loss/total, total_correct/total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-3mb0tXU-t57"
      },
      "outputs": [],
      "source": [
        "def train_model(model, epochs=10):\n",
        "    history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            X, y = preprocess(images, labels)\n",
        "\n",
        "            y_pred = model.forward(X)\n",
        "            loss = model.compute_loss(y_pred, y)\n",
        "\n",
        "            model.backward(y)\n",
        "            model.update_parameters()\n",
        "\n",
        "            preds = np.argmax(y_pred, axis=1)\n",
        "            true = np.argmax(y, axis=1)\n",
        "\n",
        "            running_loss += loss * X.shape[0]\n",
        "            correct += np.sum(preds == true)\n",
        "            total += X.shape[0]\n",
        "\n",
        "        train_loss = running_loss/total\n",
        "        train_acc = correct/total\n",
        "\n",
        "        val_loss, val_acc = model.evaluate(val_loader)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: \"\n",
        "              f\"Train Loss={train_loss:.4f}, Train Accuracy={train_acc:.4f}, \"\n",
        "              f\"Val Loss={val_loss:.4f}, Val Accuracy={val_acc:.4f}\")\n",
        "\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KNsuVr3M-v2f"
      },
      "outputs": [],
      "source": [
        "experiments = [\n",
        "    {\"lr\": 0.01, \"epochs\": 5, \"activation\": \"relu\",    \"layers\": [784, 128, 10]},\n",
        "    {\"lr\": 0.001,\"epochs\": 5, \"activation\": \"relu\",    \"layers\": [784, 128, 10]},\n",
        "    {\"lr\": 0.01, \"epochs\": 8, \"activation\": \"tanh\",    \"layers\": [784, 128, 10]},\n",
        "    {\"lr\": 0.01, \"epochs\": 8, \"activation\": \"sigmoid\", \"layers\": [784, 128, 10]},\n",
        "    {\"lr\": 0.01, \"epochs\": 8, \"activation\": \"relu\",    \"layers\": [784, 256, 128, 10]},\n",
        "    {\"lr\": 0.005,\"epochs\": 10,\"activation\": \"relu\",    \"layers\": [784, 512, 256, 10]},\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DxtPAg0C-yGF"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for images, labels in train_loader:\n",
        "            X, y = preprocess(images, labels)\n",
        "\n",
        "            y_pred = model.forward(X)\n",
        "            model.backward(y)\n",
        "            model.update_parameters()\n",
        "\n",
        "    train_loss, train_acc = model.evaluate(train_loader)\n",
        "    val_loss, val_acc = model.evaluate(val_loader)\n",
        "\n",
        "    return train_loss, train_acc, val_loss, val_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for idx, exp in enumerate(experiments):\n",
        "    print(f\"\\nRunning Experiment {idx+1}\")\n",
        "\n",
        "    model = NeuralNetwork(\n",
        "        layer_sizes=exp[\"layers\"],\n",
        "        activation=exp[\"activation\"],\n",
        "        lr=exp[\"lr\"]\n",
        "    )\n",
        "\n",
        "    train_loss, train_acc, val_loss, val_acc = train_and_evaluate(model, exp[\"epochs\"])\n",
        "\n",
        "    results.append([\n",
        "        idx+1,\n",
        "        exp[\"lr\"],\n",
        "        exp[\"epochs\"],\n",
        "        exp[\"activation\"],\n",
        "        str(exp[\"layers\"]),\n",
        "        round(train_loss,4),\n",
        "        round(train_acc,4),\n",
        "        round(val_loss,4),\n",
        "        round(val_acc,4)\n",
        "    ])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pd2z2phQNWD",
        "outputId": "7fd10e39-7b7d-4e91-fba2-c1f8f48ed7f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Experiment 1\n",
            "\n",
            "Running Experiment 2\n",
            "\n",
            "Running Experiment 3\n",
            "\n",
            "Running Experiment 4\n",
            "\n",
            "Running Experiment 5\n",
            "\n",
            "Running Experiment 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers = [\n",
        "    \"Exp#\", \"LR\", \"Epochs\", \"Activation\", \"Architecture\",\n",
        "    \"Train Loss\", \"Train Acc\", \"Val Loss\", \"Val Acc\"\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"-\"*110)\n",
        "print(\"{:<5} {:<8} {:<8} {:<10} {:<18} {:<12} {:<10} {:<10} {:<10}\".format(*headers))\n",
        "print(\"-\"*110)\n",
        "\n",
        "for row in results:\n",
        "    print(\"{:<5} {:<8} {:<8} {:<10} {:<18} {:<12} {:<10} {:<10} {:<10}\".format(*row))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qczFuq7QQPib",
        "outputId": "5715d2e7-8e33-497f-9285-02eeb9579d1b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Exp#  LR       Epochs   Activation Architecture       Train Loss   Train Acc  Val Loss   Val Acc   \n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "1     0.01     5        relu       [784, 128, 10]     0.2866       0.9191     0.2739     0.9239    \n",
            "2     0.001    5        relu       [784, 128, 10]     0.6602       0.8528     0.637      0.8609    \n",
            "3     0.01     8        tanh       [784, 128, 10]     0.2722       0.9232     0.2647     0.9259    \n",
            "4     0.01     8        sigmoid    [784, 128, 10]     0.4204       0.8894     0.4032     0.8938    \n",
            "5     0.01     8        relu       [784, 256, 128, 10] 0.1651       0.9539     0.1703     0.9491    \n",
            "6     0.005    10       relu       [784, 512, 256, 10] 0.1954       0.945      0.1931     0.9442    \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}